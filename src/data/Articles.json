ol[
    {
        "id": 1,
        "title": "Quantum Tunneling Changes Everything",
        "excerpt": "Discover how particles teleport through barriers that should be impossible to cross, revolutionizing our understanding of physics.",
        "category": "Physics",
        "author": "Maya Chen",
        "readTime": "5 min",
        "thumbnail": "https://images.unsplash.com/photo-1636466497217-26a8cbeaf0aa?w=400",
        "date": "2024-01-15"
    },
    {
        "id": 2,
        "title": "Your Brain's Hidden Orchestra", 
        "excerpt": "The surprising rhythm that controls every thought you have and how neuroscientists are decoding the brain's secret language.",
        "category": "Medicine",
        "author": "Alex Rivera",
        "readTime": "6 min", 
        "thumbnail": "https://images.unsplash.com/photo-1559757148-5c350d0d3c56?w=400",
        "date": "2024-01-14"
    },
    {
        "id": 3,
        "title": "CRISPR's New Breakthrough",
        "excerpt": "Gene editing just got a major upgrade that could change medicine forever. Here's what it means for the future.",
        "category": "Biology",
        "author": "Zara Okafor", 
        "readTime": "7 min",
        "thumbnail": "https://images.unsplash.com/photo-1576086213369-97a306d36557?w=400",
        "date": "2024-01-13"
    },
    {
        "id": 4,
        "title": "Engineering the Impossible",
        "excerpt": "From self-healing concrete to quantum computers, engineers are building the future one innovation at a time.",
        "category": "Engineering",
        "author": "Jordan Park",
        "readTime": "8 min",
        "thumbnail": "https://images.unsplash.com/photo-1581092921461-eab62e97a780?w=400", 
        "date": "2024-01-12"
    },
    {
        "id": 5,
        "title": "Dark Matter's Biggest Mystery",
        "excerpt": "We found something that shouldn't exist, and it's everywhere. The latest discoveries are rewriting physics textbooks.",
        "category": "Astronomy", 
        "author": "Sam Chen",
        "readTime": "9 min",
        "thumbnail": "https://images.unsplash.com/photo-1446776653964-20c1d3a81b06?w=400",
        "date": "2024-01-11"
    },
    {
        "id": 6,
        "title": "The Chemistry of Emotions",
        "excerpt": "How molecular reactions in your brain create feelings, and why understanding this chemistry could change mental health treatment.",
        "category": "Chemistry",
        "author": "Riley Martinez",
        "readTime": "6 min",
        "thumbnail": "https://images.unsplash.com/photo-1532187863486-abf9dbad1b69?w=400",
        "date": "2024-01-10"
    },
    {
        "id": 7,
        "title": "Machine Learning in Our Lives",
        "excerpt": "Machine learning is a subset of artificial intelligence that is able to learn patterns and correlations in data.",
        "category": "Technology",
        "author": "Ayush Srivastava",
        "readTime": "6 min",
        "thumbnail": "https://media.istockphoto.com/id/1448152453/vector/big-data-technology-and-data-science-illustration-data-flow-concept-querying-analysing.jpg?s=612x612&w=0&k=20&c=To0lhCrVmDYdSkOUOGxGsjlYe0buj_wwGCDqYhF9p2o=",
        "date": "2025-7-28",
        "content": "Machine learning is often a foreign concept to many, yet it is integrated into numerous applications we use daily. Various social media platforms, videos on YouTube, and even products on Amazon utilize machine learning. This subset of artificial intelligence has quietly positioned itself close into the center of our daily lives, enabling us to interact with it daily.\n\nThe realm of artificial intelligence includes numerous subfields, one of which being machine learning. Machine learning allows systems to actually learn patterns and correlations from data and make predictions and decisions based on what they receive. Machine learning is able to analyze huge amounts of data to determine patterns or trends in an extremely short amount of time - in fact, the more amount of data the machine learning algorithm contains, the more likely its accuracy will increase. \n\nMachine learning is a learning process that is achieved through the implementation of machine learning models. These models are no more than mathematical formulas - usually complex ones which we don’t need to delve into. These models analyze large amounts of data to improve their prediction accuracy and performance over time without being explicitly programmed. A simple way to think about it is this: imagine a scenario where a small child must classify planes and cars. Rather than just instructing the child that planes have wings, a long body, a tail, and can fly, while cars are much smaller, have no wings or tail, and do not fly, the child is instead given hundreds or thousands of images of either cars or planes. Over time, as the amount of data grows, the child is able to recognize and detect these differences between the car and the plane. This is the heart of machine learning. The ML models learn from the data they’re given through two main learning processes. \n\nThe first method is supervised learning. In this method of learning, all of the data contains labels. Going back to the car vs. plane example, if a ML model was given this data and told to analyze it with supervised learning, all of the data would contain labels, such as “car” or “plane.” The model is able to easily identify which picture is a car or plane based on the label and, through this, is able to detect any differences between the car and the plane and classify accordingly. Numerous practical applications exist for this method of learning for ML models, including medical diagnosis, fraud detection, marketing, and more. \n\nThe second method is through unsupervised learning, which is the exact opposite of supervised learning. In unsupervised learning, labels do not exist for the data - indicating that when the data is passed to the model, the model does not know the labels. The ML model must be able to detect any hidden patterns, correlations, or relationships without any prior experience or examples. Imagine an adult working to analyze consumer spending behaviors. This adult mainly specializes in finding sets of items that are bought together or occur frequently together in consumer purchases. The adult would be that, the majority of the time, consumers buy bread and butter together at the store. Obviously, the relationships that must be determined are much more complex than the one just given - or else why would one need this learning method of machine learning? In this method, the model teaches itself the similarities, differences, and groupings within the dataset. Applications for this method of machine learning include clustering of people based on their types of behavior in different situations (e.g. purchasing, panic, etc.), aiding in customer segmentation for businesses, along with detections in cybersecurity, and even genomic data analysis. \n\nNow, ML models operate through a series of layers containing neurons. The first layer, called the input layer, receives the data. Through this data, the machine learning process is initialized. Next, the model contains one or more hidden layers, which is where core learning and pattern extraction occurs. The more hidden layers a ML model has, the “smarter” it becomes, allowing it to better extrapolate relationships in the data given in the input layer. A model with 10 hidden layers would be able to find distinct correlations in the data much better than a model with only one input layer. However, this model will also run slower than a model with 1 hidden layer due to an increase in training time. Finally, the last layer is the output layer, which consists of the model’s prediction on the data initially given in the input layer. \n\nModels usually operate on training and testing data. To provide accurate results, it is essential that the testing portion is wholly different from the training portion. During the training portion, the data enters the input layer and passes through the hidden layer. In the output layer, models incorporate a loss function. In this step, the loss function measures the model’s predictions against the actual value in supervised learning, while in unsupervised learning, the loss function measures how well the model was able to extrapolate relationships and correlations in the data. Based on these results, the model updates the hidden layer accordingly in order to improve its results on the next portion of the training dataset. \n\nThe testing portion includes data being passed through the input layer and analyzed by the hidden layer. This step is crucial as the training of the hidden layer functions indicate how well the model is able to detect relationships and make predictions on the data. Finally, a prediction is passed through the output layer. \n\nML models are not always 100% accurate - in fact they often are never 100% accurate. To achieve this accuracy, models must be completely right, which means that their hidden layer must be perfect. This is not always the case. To improve accuracy, one must have lots of data in order for the functions in the hidden layer to adjust themselves in the training phase, along with lots of hidden layers as well. By including these features, one can easily improve the accuracy of a ML model. \n\nMachine learning is no longer a futuristic concept - it’s currently being utilized by companies, organizations and researchers across the globe and has already positioned itself in the midst of our everyday lives. Amazon is able to push products towards us through these models, using our previous purchase history as the data. Most importantly, they are able to do this without any human intervention, highlighting the goal of building systems that can adapt and improve on their own. Even without labeled data, ML models are still able to detect anomalies and relationships in data. However, although ML may sound powerful, it is critical to understand its limitations and drawbacks as well. The utilization of machine learning wisely and efficiently is the future of our community. "
    },
    {
        "id": 8,
        "title": "A Universe-Sized Crunch Bar",
        "excerpt": "Discover the ways that the universe could end and how it began - with a delicious candy bar.",
        "category": "Physics",
        "author": "Medhansh Garadala",
        "readTime": "5 min",
        "thumbnail": "https://bigthink.com/wp-content/uploads/2021/09/https___blogs-images.forbes.com_startswithabang_files_2016_06_Observable_universe_logarithmic_illustration.png",
        "date": "2025-07-29",
        "content": "It’s Halloween right now, and you just went trick-or-treating. You’re sweaty, tired, and hauling a big, fat load of candy—so close to just dropping it down and eating it all. And you do just that. Sitting down on a patch of grass, you dig into your pillowcase to find a big blue, king-size Crunch bar. Oh boy. It looks delicious. So, like any chocolate-loving kid, you tear apart the wrapper and bite into the bar. At first it’s good. Real good. It’s crispy, popping all over your mouth and silky smooth. But after a few seconds, it collapses into just crumbs and sugar. It’s gone. That’s what some scientists think will happen to the universe. A Big Crunch. \n\nBut to understand the end, we have to understand the beginning. The beginning for our universe lies within the Big Bang, or the first bite of the bar. Every single thing, time, space, matter, was all compressed into a singularity. “An infinitely dense, infinitely hot point.” Then something triggered. In a fraction of a second, existence itself was born, and the universe expanded faster than the speed of light, unstoppable and vast. \n\nAs the expansion cooled down, the universe worked its magic into creating particles, atoms, planets, stars, galaxies and a special something that breathes within us: life. The flash from beyond 13.8 billion years still echoes today in the Cosmic Microwave Background, a dim glow that remains from a baby universe. Gravity sculpted for eons, forming galaxies like ours, but the story doesn’t stop there. Something interesting was happening as reality was organizing itself. \n\nThe universe wasn’t only expanding, but accelerating. Why? It was because of the invisible push, also known as dark energy. Making up approximately 68% of the universe, it acts as a force that divides. Galaxies race away from each other while the universe stretches away like pizza dough every second. \n\nSo now comes the end. There could be either a crunch, a frozen treat, or a ripped piece of licorice waiting for us at the end of existence. A common theory is the Big Freeze, also known as the heat death of the universe. What if the universe continues to expand forever? Billions and trillions of years of expansion. Every star runs out of fuel, galaxies drift apart too far for interaction, and all that’s left is an empty, cold infinitely expanding space. \n\nAnother would be the Big Crunch, where dark energy weakens and gravity becomes the king, gaining control and pulling everything inward. Collisions, sparks, and heat. Space-time collapses on itself. Everything clusters back into the original point. A dramatic finish for the Universe. \n\nThe last and most violent death would be a Big Rip, where instead of gravity being king, its dark energy. And as it becomes stronger and stronger, it tears apart galaxy clusters, solar systems, planets, atoms, and space-time itself. The tear doesn’t stop until the universe is in shreds. \n\nSo what does this do with a Crunch bar? It’s a simple metaphor for saying how we live inside a cosmic candy, caught between the snap of its beginning and the crumble of its end. \n\nShould you blame yourself or entropy? \n\nYou’re eight years old playing baseball out in the yard. As your friend winds up his fastball, you focus. As the ball comes flying towards you, you swing as hard as you can. It hit the sweet spot and was flying higher and higher…towards a window. Panicked, you rush to your house and see that your mother’s favorite vase was on the ground, broken. She rushes up from the basement. “Did you do this?” she asks you. With no one else to pin it on, you take the blame. \n\nBut was it really your fault? Or was it entropy?"
    }
]
